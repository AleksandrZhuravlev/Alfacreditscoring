{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель кредитного  скоринга для магистратуры Альфа-Банк + МФТИ\n",
    "### разработал Журавлев Александр, студент НГУ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gc import collect\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "#import pyarrow\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold , cross_validate\n",
    "from lightgbm import plot_importance\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier \n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.integration import CatBoostPruningCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импорт данных\n",
    "### импорт в 2 датафрейма, оперативной памяти не хватило чтобы обработать все данные в одном"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_0=pd.concat([pd.read_parquet('train_data_7.pq'),\n",
    "                     pd.read_parquet('train_data_8.pq'),pd.read_parquet('train_data_9.pq'),\n",
    "                     pd.read_parquet('train_data_10.pq'),pd.read_parquet('train_data_11.pq'),\n",
    "                     ],ignore_index=True)\n",
    "#train_data_0.drop(train_data_0[train_data_0['rn']>25].index,axis=0,inplace=True)\n",
    "#train_data_0.drop(['pre_since_opened','pre_since_confirmed','pre_till_pclose'],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "train_data_1=pd.concat([pd.read_parquet('train_data_1.pq'),\n",
    "                     pd.read_parquet('train_data_0.pq'),pd.read_parquet('train_data_2.pq'),\n",
    "                     pd.read_parquet('train_data_3.pq'),pd.read_parquet('train_data_4.pq'),\n",
    "                     pd.read_parquet('train_data_5.pq'),pd.read_parquet('train_data_6.pq'),\n",
    "                     ],ignore_index=True)\n",
    "\n",
    "target_train=pd.read_csv('train_target.csv')\n",
    "target_test=pd.read_csv('test_target.csv')\n",
    "test_id=pd.read_csv('test_target.csv')\n",
    "test_data=pd.concat([pd.read_parquet('test_data_0.pq'),pd.read_parquet('test_data_1.pq')],ignore_index=True)\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разведывательный анализ исходных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_0.describe()\n",
    "#train_data_1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_0.info()\n",
    "#train_data_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_0.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Аггрегирование категориальных признаков в сумму фиктивных переменных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def aggregations( data_frame: pd.DataFrame):\n",
    "    \n",
    "    feature_columns = list(data_frame.columns.values)\n",
    "    feature_columns.remove(\"id\"), feature_columns.remove(\"rn\")\n",
    "    dummies = pd.get_dummies(data_frame[feature_columns], columns=feature_columns)\n",
    "    dummy_features = dummies.columns.values\n",
    "    ohe_features = pd.concat([data_frame, dummies], axis=1)\n",
    "    ohe_features = ohe_features.drop(columns=feature_columns)\n",
    "    ohe_features.groupby(\"id\")\n",
    "    features = ohe_features.groupby(\"id\")[dummy_features].sum().reset_index(drop=False)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_0=aggregations(train_data_0)\n",
    "train_df_0=target_train.merge(features_0,on='id')\n",
    "feature_cols0=list(train_df_0.columns.values)\n",
    "feature_cols0.remove(\"id\"), feature_cols0.remove(\"flag\")\n",
    "y0=train_df_0['flag'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_1=aggregations(train_data_1)\n",
    "train_df_1=target_train.merge(features_1,on='id')\n",
    "feature_cols1=list(train_df_1.columns.values)\n",
    "feature_cols1.remove(\"id\"), feature_cols1.remove(\"flag\")\n",
    "y1=train_df_1['flag'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df=pd.concat([train_df_0,train_df_1])\n",
    "y0df=pd.DataFrame(y0,columns=['flag'])\n",
    "y1df=pd.DataFrame(y1,columns=['flag'])\n",
    "y=pd.concat([y0df,y1df])['flag'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### сопоставляем данные колонки для свопадения размерности в train и test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_sub=aggregations(test_data)\n",
    "\n",
    "\n",
    "feature_cols_sub=list(features_sub.columns.values)\n",
    "feature_cols_sub.remove('id')\n",
    "\n",
    "feature_cols_both=list(set(feature_cols0) & set(feature_cols1) & set(feature_cols_sub))\n",
    "\n",
    "X=train_df[feature_cols_both]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y,\n",
    "                                                  test_size=0.2,stratify=y,\n",
    "                                                  random_state=42)\n",
    "del features_0, features_1,  train_df_0, train_df_1, train_data_0, train_data_1\n",
    "collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# catboost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## catboost optuna optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    param = {\n",
    "        'iterations': 1500,\n",
    "        'learning_rate' : trial.suggest_int ('learning_rate',0.001,0.1),\n",
    "        \"objective\": trial.suggest_categorical(\"objective\", [\"Logloss\"]),\n",
    "        'od_wait':trial.suggest_int('od_wait', 1, 100),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 1, 30),\n",
    "        'reg_lambda': trial.suggest_uniform('reg_lambda',1e-5,100),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf',1,100),\n",
    "        'random_strength': trial.suggest_float('random_strength',1,100),\n",
    "        \"bootstrap_type\": trial.suggest_categorical(\n",
    "            \"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]\n",
    "        ),\n",
    "        \n",
    "        \n",
    "        \"task_type\":\"GPU\",\n",
    "        \n",
    "    }\n",
    "    if param[\"bootstrap_type\"] == \"Bayesian\":\n",
    "        param[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 10)\n",
    "    elif param[\"bootstrap_type\"] == \"Bernoulli\":\n",
    "        param[\"subsample\"] = trial.suggest_float(\"subsample\", 0.01, 10, log=True)\n",
    "\n",
    "\n",
    "    cv = StratifiedKFold(shuffle=True, random_state=42, n_splits=4)\n",
    "\n",
    "    model2 = CatBoostClassifier(**param)\n",
    "\n",
    "    cross_valid = cross_validate(model2, X, y, scoring='roc_auc', cv=cv, return_estimator=True)\n",
    "    \n",
    "    print(cross_valid['test_score'])\n",
    "\n",
    " \n",
    "    return min(cross_valid['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = TPESampler(seed=1)\n",
    "study = optuna.create_study(study_name=\"catboost\", direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(objective, n_trials=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGboost "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baseline модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    "    'device' : 'cuda',\n",
    "    'verbosity' : 1,\n",
    "    'alpha': 48,\n",
    "    'eta' : 0.003, # learning rate\n",
    "    'max_depth' : 49,\n",
    "    'gamma' : 2, # lareger - less overfit\n",
    "    'min_child_weight' : 1.5, # lareger - less overfit, more conservatrive default 1\n",
    "    'subsample' : 0.5,\n",
    "    # 'lambda' : 33,\n",
    "    'tree_method' : 'hist',\n",
    "    'objective' : 'binary:logistic',\n",
    "    'eval_metric' : 'auc',\n",
    "    #'num_round' : 1000,\n",
    "    #'early_stopping_rounds' : 150,\n",
    "    'seed' : 42,\n",
    "    'n_estimators' : 16000,\n",
    "\n",
    "}\n",
    "\n",
    "model2=XGBClassifier(**params)\n",
    "model2.fit(X_train,y_train,verbose=True,eval_set=[(X_val, y_val)]) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_val, model2.predict_proba(X_val)[:,1])\n",
    "# 0.771165896084853  rn >20\n",
    "# 0.7717232977884556 rn >23\n",
    "# 0.7717340881028871 rn >24\n",
    "# 0.7714754061297703 rn >25, without na cols\n",
    "# 0.7722474759161622 rn >25 BEST,  0.7719390458455615 0.77177\n",
    "# 0.772066303790381 rn >26\n",
    "# 0.7719874717352808 rn >27\n",
    "# 0.7720687457916587 rn >30\n",
    "# 0.7720268479841006 rn >42 0.7718465577887845\n",
    "# 0.7718815699102753 all features\n",
    "# 0.771790192380146 rn >36\n",
    "# 0.772010203020203 rn not cut off \n",
    "# 0.7721663311507744 rn not cut off and na to 0\n",
    "#0.7684390792514973"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    dtrain=xgb.DMatrix(X, label = y)\n",
    "    param = {\n",
    "        \"n_estimators\" : trial.suggest_int(\"n_estimators\", 100, 15000),\n",
    "        'random_state': trial.suggest_categorical('random_state', [42]),\n",
    "        \"device\" : \"cuda\",\n",
    "        \"verbosity\": 1,\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"gblinear\",\"dart\"]),\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 50.0, log=True),\n",
    "    }\n",
    "    if param[\"booster\"] == \"gbtree\" or param[\"booster\"] == \"dart\":\n",
    "        param[\"max_depth\"] = trial.suggest_int(\"max_depth\", 1, 45)\n",
    "        param[\"eta\"] = trial.suggest_float(\"eta\", 1e-8, 1.0, log=True)\n",
    "        param[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True)\n",
    "        param[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
    "    if param[\"booster\"] == \"dart\":\n",
    "        param[\"sample_type\"] = trial.suggest_categorical(\"sample_type\", [\"uniform\", \"weighted\"])\n",
    "        param[\"normalize_type\"] = trial.suggest_categorical(\"normalize_type\", [\"tree\", \"forest\"])\n",
    "        param[\"rate_drop\"] = trial.suggest_float(\"rate_drop\", 1e-8, 1.0, log=True)\n",
    "        param[\"skip_drop\"] = trial.suggest_float(\"skip_drop\", 1e-8, 1.0, log=True)\n",
    "    \n",
    "    pruning_callback = optuna.integration.XGBoostPruningCallback(trial, \"test-auc\")\n",
    "    history = xgb.cv(param, dtrain,  callbacks=[pruning_callback],early_stopping_rounds=50)\n",
    "    mean_auc = history[\"test-auc-mean\"].values[-1]\n",
    "    return mean_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruner = optuna.pruners.HyperbandPruner()\n",
    "study = optuna.create_study(pruner=pruner, direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=500)\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отправка результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_features=extract_count_aggregations(test_data)\n",
    "\n",
    "X_sub=test_features[feature_cols_both]\n",
    "X_sub.fillna(0,inplace=True)\n",
    "\n",
    "preds=model2.predict_proba(X_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub.isna().sum().nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"id\" : test_id[\"id\"].values,\n",
    "    \"score\": preds[:,1]\n",
    "}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv',index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
